{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T16:47:16.549472Z",
     "start_time": "2024-11-06T16:47:15.824472Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from newspaper import Article\n",
    "from tqdm import tqdm\n",
    "# pip install newspaper3k, lxml, lxml-html-clean"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_user_agent():\n",
    "    \"\"\"Returns a random user agent.\"\"\"\n",
    "    available = (\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:102.0) Gecko/20100101 Firefox/102.0',\n",
    "        'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/116.0',\n",
    "    )\n",
    "    return available[random.randint(0, len(available) -1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T16:47:16.555972Z",
     "start_time": "2024-11-06T16:47:16.550973Z"
    }
   },
   "id": "518776518c8d944f",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "default_headers = {\n",
    "    'User-Agent': get_user_agent(),\n",
    "    'Accept': 'text/html',\n",
    "    'Accept-Language': 'en-US',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://www.google.com',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'DNT': '1'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T16:47:16.562973Z",
     "start_time": "2024-11-06T16:47:16.556973Z"
    }
   },
   "id": "62cd38aa8fc967b0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=64)\n",
    "def get_text(link: str):   \n",
    "    a = Article(\n",
    "        link, \n",
    "        headers=default_headers,\n",
    "        fetch_images=False\n",
    "    )\n",
    "    a.download()\n",
    "    a.parse()\n",
    "    return a.text, a.tags"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T16:47:16.568472Z",
     "start_time": "2024-11-06T16:47:16.564474Z"
    }
   },
   "id": "2e86b75d49817afb",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "exclusion = [\n",
    "    'youtube.com'\n",
    "]\n",
    "\n",
    "def __exclude(link: str):\n",
    "    # check if link is blacklisted\n",
    "    parsed = urlparse(link)\n",
    "    domain = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed)\n",
    "    \n",
    "    if domain.startswith('https://www.'):\n",
    "        domain = domain[len('https://www.'):]\n",
    "    if domain.endswith('/'):\n",
    "        domain = domain.replace('/', '')\n",
    "\n",
    "    return domain in exclusion\n",
    "\n",
    "\n",
    "def google_search(search_query, results = 3, timeout: int = 3):\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            url=\"https://www.google.com/search\",\n",
    "            headers=default_headers,\n",
    "            params={\n",
    "                \"q\": search_query,\n",
    "                \"num\": results,\n",
    "                \"start\": 0,\n",
    "                \"safe\": \"active\",\n",
    "            },\n",
    "            timeout=timeout,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "    except requests.HTTPError as req_err:\n",
    "        print(f'[!] Error: {req_err}')\n",
    "        return \n",
    "        \n",
    "    # Parse\n",
    "    links = set()\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    result_block = soup.find_all(\"div\", attrs={\"class\": \"g\"})\n",
    "    for result in result_block:\n",
    "        link = result.find(\"a\", href=True)\n",
    "        if link and not __exclude(link['href']):\n",
    "            \n",
    "            links.add(link[\"href\"])\n",
    "    return list(links)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:10:22.723520Z",
     "start_time": "2024-11-06T17:10:22.715986Z"
    }
   },
   "id": "125f7b20731b5f7b",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "links = google_search('Apache Log Poisoning')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:10:25.951514Z",
     "start_time": "2024-11-06T17:10:23.296803Z"
    }
   },
   "id": "b7dd3af9fa19c8ac",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['https://www.hackingarticles.in/apache-log-poisoning-through-lfi/',\n 'https://attackdefense.com/challengedetails?cid=916']"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T17:10:26.411285Z",
     "start_time": "2024-11-06T17:10:26.407755Z"
    }
   },
   "id": "84260d00ceacbb10",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T14:35:33.373809Z",
     "start_time": "2024-11-02T14:35:33.368307Z"
    }
   },
   "id": "cb1016e3653a148d",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1409/1409 [11:13<00:00,  2.09step/s]\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(total=len(links), unit=\"step\")\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(get_text, lnk) for lnk in links]\n",
    "    for future in as_completed(futures):\n",
    "        future.result()\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.refresh()\n",
    "progress_bar.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T14:46:46.560477Z",
     "start_time": "2024-11-02T14:35:33.375309Z"
    }
   },
   "id": "841419580f7136ea",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T14:46:46.564978Z",
     "start_time": "2024-11-02T14:46:46.562477Z"
    }
   },
   "id": "441285bba7f513dc",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
